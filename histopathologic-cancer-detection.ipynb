{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11848,"databundleVersionId":862157,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-01T21:44:20.568803Z","iopub.execute_input":"2025-06-01T21:44:20.569370Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ─── Cell 1: verify that Kaggle has mounted everything  ─────────────────────────\nimport os\n\nINPUT_DIR = \"/kaggle/input/histopathologic-cancer-detection\"\nprint(\"Contents of /kaggle/input/histopathologic-cancer-detection/:\")\nfor fname in sorted(os.listdir(INPUT_DIR)):\n    print(\"  \", fname)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T22:06:00.193165Z","iopub.execute_input":"2025-06-01T22:06:00.193415Z","iopub.status.idle":"2025-06-01T22:06:00.206546Z","shell.execute_reply.started":"2025-06-01T22:06:00.193396Z","shell.execute_reply":"2025-06-01T22:06:00.205897Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ─── Cell 2: read the CSV of training labels ───────────────────────────────────────────\nimport pandas as pd\n\nlabels_df = pd.read_csv(os.path.join(INPUT_DIR, \"train_labels.csv\"))\nprint(\"Total train_labels rows:\", len(labels_df))\nprint(labels_df[\"label\"].value_counts())\nlabels_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T22:06:02.903266Z","iopub.execute_input":"2025-06-01T22:06:02.903768Z","iopub.status.idle":"2025-06-01T22:06:04.993051Z","shell.execute_reply.started":"2025-06-01T22:06:02.903747Z","shell.execute_reply":"2025-06-01T22:06:04.992218Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ─── Cell 3: inspect “train/” folder structure and show a few random images ─────────────\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nTRAIN_DIR = os.path.join(INPUT_DIR, \"train\")\nall_train_files = [f for f in os.listdir(TRAIN_DIR) if f.lower().endswith(\".tif\")]\nprint(\"Number of .tif files in train/:\", len(all_train_files))\nprint(\"Example filenames:\", all_train_files[:5])\n\n# Define a small helper to load a patch directly from train/\ndef load_patch(train_dir, patch_id):\n    \"\"\"\n    patch_id is the 40-char string (without “.tif”). \n    We assume train/ contains exactly files named \"<patch_id>.tif\".\n    \"\"\"\n    full_path = os.path.join(train_dir, patch_id + \".tif\")\n    img = Image.open(full_path).convert(\"RGB\")\n    return img\n\n# Display 4 random train patches (2 positives, 2 negatives)\nplt.figure(figsize=(8, 8))\nfor i in range(4):\n    # pick a random row in labels_df \n    idx = random.randint(0, len(labels_df) - 1)\n    pid = labels_df.loc[idx, \"id\"]\n    lab = labels_df.loc[idx, \"label\"]\n    patch_img = load_patch(TRAIN_DIR, pid)\n    ax = plt.subplot(2, 2, i+1)\n    ax.imshow(patch_img)\n    ax.set_title(f\"id={pid[:8]}…  label={lab}\")\n    ax.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T22:06:06.870399Z","iopub.execute_input":"2025-06-01T22:06:06.870918Z","iopub.status.idle":"2025-06-01T22:06:10.533263Z","shell.execute_reply.started":"2025-06-01T22:06:06.870897Z","shell.execute_reply":"2025-06-01T22:06:10.532581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ─── Cell 4: same for “test/”—peek at a few test images (unlabeled) ───────────────────\nTEST_DIR = os.path.join(INPUT_DIR, \"test\")\nall_test_files = [f for f in os.listdir(TEST_DIR) if f.lower().endswith(\".tif\")]\nprint(\"Number of .tif files in test/:\", len(all_test_files))\nprint(\"First 5 test filenames:\", all_test_files[:5])\n\n# Display 4 random “test” patches (though unlabeled, just for sanity check)\nplt.figure(figsize=(8, 8))\nfor i in range(4):\n    tfn = random.choice(all_test_files)\n    img = Image.open(os.path.join(TEST_DIR, tfn)).convert(\"RGB\")\n    ax = plt.subplot(2, 2, i+1)\n    ax.imshow(img)\n    ax.set_title(f\"test/{tfn[:8]}…\")\n    ax.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T22:06:13.742819Z","iopub.execute_input":"2025-06-01T22:06:13.743088Z","iopub.status.idle":"2025-06-01T22:06:14.908312Z","shell.execute_reply.started":"2025-06-01T22:06:13.743067Z","shell.execute_reply":"2025-06-01T22:06:14.907611Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ─── Cell 5: Quick class‐balance bar chart for the train set ────────────────────────────\ncounts = labels_df[\"label\"].value_counts()\nplt.figure(figsize=(4, 4))\nplt.bar([\"Non-Metastasis (0)\", \"Metastasis (1)\"], counts.values, color=[\"steelblue\",\"crimson\"])\nplt.ylabel(\"Count of Patches\")\nplt.title(\"Class Distribution in the 220k-patch Train Set\")\nfor i, v in enumerate(counts.values):\n    plt.text(i, v + 2000, str(v), ha=\"center\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T22:06:17.434523Z","iopub.execute_input":"2025-06-01T22:06:17.435068Z","iopub.status.idle":"2025-06-01T22:06:17.557112Z","shell.execute_reply.started":"2025-06-01T22:06:17.435045Z","shell.execute_reply":"2025-06-01T22:06:17.556476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ─── Cell 6: build a PyTorch Dataset/output DataLoader (since \"train/\" is already unzipped)\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nclass HistopathFolderDataset(Dataset):\n    def __init__(self, labels_df, train_folder, transform=None):\n        super().__init__()\n        self.df = labels_df.reset_index(drop=True)\n        self.train_folder = train_folder\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        patch_id = row[\"id\"]\n        label = torch.tensor(row[\"label\"], dtype=torch.float32)\n        img_path = os.path.join(self.train_folder, patch_id + \".tif\")\n        img = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img, label\n\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\nnsamp = 2000\nrng = np.random.default_rng(seed=42)\nindices = rng.choice(len(labels_df), size=nsamp, replace=False)\n\nmeans = []\nstds = []\nfor i in indices:\n    pid = labels_df.loc[i, \"id\"]\n    arr = np.array(\n        Image.open(os.path.join(TRAIN_DIR, pid + \".tif\")).convert(\"RGB\")\n    ).astype(np.float32) / 255.0\n    means.append(arr.mean(axis=(0,1)))\n    stds.append(arr.std(axis=(0,1)))\nmeans = np.vstack(means)\nstds  = np.vstack(stds)\nglobal_mean = means.mean(axis=0).tolist()\nglobal_std  = stds.mean(axis=0).tolist()\nprint(\"Global mean:\", global_mean)\nprint(\"Global std: \", global_std)\n\ntrain_df, val_df = train_test_split(\n    labels_df, test_size=0.20, stratify=labels_df[\"label\"], random_state=42\n)\n\ntrain_transforms = transforms.Compose([\n    transforms.Resize((96,96)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=global_mean, std=global_std),\n])\nval_transforms = transforms.Compose([\n    transforms.Resize((96,96)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=global_mean, std=global_std),\n])\n\ntrain_ds = HistopathFolderDataset(train_df, TRAIN_DIR, transform=train_transforms)\nval_ds   = HistopathFolderDataset(val_df,   TRAIN_DIR, transform=val_transforms)\n\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True,  num_workers=2, pin_memory=True)\nval_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n\nprint(\"Train batches per epoch:\", len(train_loader))\nprint(\"Val   batches per epoch:\", len(val_loader))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T22:06:19.865901Z","iopub.execute_input":"2025-06-01T22:06:19.866605Z","iopub.status.idle":"2025-06-01T22:06:45.314049Z","shell.execute_reply.started":"2025-06-01T22:06:19.866579Z","shell.execute_reply":"2025-06-01T22:06:45.313288Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ─── Cell 7: Quick EDA / Patch Visualization (using .iloc and skipping missing files) ────────────────────────\n\nimport random\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nplt.figure(figsize=(10,4))\n\nshown = 0\nattempts = 0\nmax_attempts = 30    # stop if we can’t find 6 valid files after 30 tries\n\nwhile shown < 6 and attempts < max_attempts:\n    attempts += 1\n    pos = random.randint(0, len(train_df) - 1)\n    pid = train_df.iloc[pos][\"id\"]\n    lbl = train_df.iloc[pos][\"label\"]\n    img_path = os.path.join(TRAIN_DIR, pid + \".tif\")\n\n    if not os.path.isfile(img_path):\n        continue\n\n    try:\n        img = Image.open(img_path).convert(\"RGB\")\n    except Exception:\n        continue\n\n    ax = plt.subplot(2, 3, shown + 1)\n    ax.imshow(img)\n    ax.set_title(f\"Label = {lbl}\")\n    ax.axis(\"off\")\n\n    shown += 1\n\nif shown < 6:\n    print(f\"Only {shown} valid patches were found after {attempts} attempts.\")\n\nplt.suptitle(\"Six Random Training Patches\", fontsize=16)\nplt.tight_layout(rect=[0,0,1,0.9])\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T22:06:52.328725Z","iopub.execute_input":"2025-06-01T22:06:52.329424Z","iopub.status.idle":"2025-06-01T22:06:52.703264Z","shell.execute_reply.started":"2025-06-01T22:06:52.329399Z","shell.execute_reply":"2025-06-01T22:06:52.702456Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ─── Cell 8: Define a Simple CNN Model ─────────────────────────────────────────────\n\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass TinyCNN(nn.Module):\n    def __init__(self):\n        super(TinyCNN, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),  # → 16×96×96\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2,2),                                       # → 16×48×48\n\n            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),  # → 32×48×48\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2,2),                                       # → 32×24×24\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),                                            # → 32×24×24 = 18432\n            nn.Linear(32*24*24, 64),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(64, 1)   # output raw logit\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = TinyCNN().to(device)\nprint(\"Model architecture:\", model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T22:06:56.121960Z","iopub.execute_input":"2025-06-01T22:06:56.122684Z","iopub.status.idle":"2025-06-01T22:06:56.352078Z","shell.execute_reply.started":"2025-06-01T22:06:56.122658Z","shell.execute_reply":"2025-06-01T22:06:56.351445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ─── Cell 9: Loss, Optimizer, and a Mini‐Batch AUC Helper (on small subsets) ─────\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\ndef compute_subset_auc(model, loader, device, subset_size=512):\n    \"\"\"\n    Runs inference on at most `subset_size` samples (not the full loader)\n    to get a quick AUC estimate.\n    \"\"\"\n    model.eval()\n    collected_logits = []\n    collected_labels = []\n    seen = 0\n\n    with torch.no_grad():\n        for images, labels in loader:\n            b = images.size(0)\n            if seen + b > subset_size:\n                take = subset_size - seen\n                images = images[:take]\n                labels = labels[:take]\n                b = take\n\n            images = images.to(device)\n            labels = labels.to(device).view(-1)\n            logits = model(images).squeeze(1).cpu().numpy()\n            collected_logits.append(logits)\n            collected_labels.append(labels.cpu().numpy())\n            seen += b\n\n            if seen >= subset_size:\n                break\n\n    all_logits = np.concatenate(collected_logits, axis=0)\n    all_labels = np.concatenate(collected_labels, axis=0)\n    probs = 1.0 / (1.0 + np.exp(-all_logits))\n    auc = roc_auc_score(all_labels, probs)\n    return auc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T22:06:58.981312Z","iopub.execute_input":"2025-06-01T22:06:58.981609Z","iopub.status.idle":"2025-06-01T22:06:58.988722Z","shell.execute_reply.started":"2025-06-01T22:06:58.981589Z","shell.execute_reply":"2025-06-01T22:06:58.988032Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ─── Cell 10: Full 5‐Epoch Training Loop ─────────────────────────────────\n\nnum_epochs = 5\ntrain_losses      = []\ntrain_subset_aucs = []\nval_subset_aucs   = []\n\nfor epoch in range(1, num_epochs + 1):\n    print(f\"\\n→ Starting Epoch {epoch}/{num_epochs}\")\n    model.train()\n    running_loss = 0.0\n\n    for batch_idx, (images, labels) in enumerate(train_loader, start=1):\n        images = images.to(device)\n        labels = labels.to(device).unsqueeze(1)\n\n        optimizer.zero_grad()\n        logits = model(images)\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * images.size(0)\n\n        if batch_idx % 500 == 0:\n            print(f\"   Batch {batch_idx}/{len(train_loader)} →  loss {loss.item():.4f}\")\n\n    epoch_loss = running_loss / len(train_loader.dataset)\n    train_losses.append(epoch_loss)\n    print(f\"→ Epoch {epoch} done. Avg. loss (full epoch): {epoch_loss:.4f}\")\n\n    train_auc = compute_subset_auc(model, train_loader, device, subset_size=1000)\n    val_auc   = compute_subset_auc(model, val_loader,   device, subset_size=1000)\n    train_subset_aucs.append(train_auc)\n    val_subset_aucs.append(val_auc)\n\n    print(f\"→ Epoch {epoch} summary: Train Loss = {epoch_loss:.4f}   \"\n          f\"TrainSubset AUC = {train_auc:.4f}   ValSubset AUC = {val_auc:.4f}\")\n\nprint(f\"\\n===== Finished {num_epochs} epochs. Best val‐subset AUC ≈ {max(val_subset_aucs):.4f} =====\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T22:07:04.965947Z","iopub.execute_input":"2025-06-01T22:07:04.966531Z","iopub.status.idle":"2025-06-01T22:28:54.779235Z","shell.execute_reply.started":"2025-06-01T22:07:04.966507Z","shell.execute_reply":"2025-06-01T22:28:54.778438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ─── Cell 11: Plot Training Loss and AUC Curves ──────────────────────────────────\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nepochs = np.arange(1, len(train_losses) + 1)\n\nplt.figure(figsize=(12, 5))\n\n# Plot training loss over epochs\nplt.subplot(1, 2, 1)\nplt.plot(epochs, train_losses, marker='o', color='darkblue', label=\"Train Loss\")\nplt.title(\"Training Loss over Epochs\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.grid(True)\nplt.legend()\n\n# Plot subset‐AUC over epochs (train‐subset vs. val‐subset)\nplt.subplot(1, 2, 2)\nplt.plot(epochs, train_subset_aucs, marker='o', color='forestgreen', label=\"Train‐subset AUC\")\nplt.plot(epochs, val_subset_aucs,   marker='o', color='firebrick',  label=\"Val‐subset AUC\")\nplt.title(\"Subset AUC over Epochs\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"AUC\")\nplt.ylim(0.5, 1.0)\nplt.grid(True)\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T22:30:51.454136Z","iopub.execute_input":"2025-06-01T22:30:51.454953Z","iopub.status.idle":"2025-06-01T22:30:51.813759Z","shell.execute_reply.started":"2025-06-01T22:30:51.454924Z","shell.execute_reply":"2025-06-01T22:30:51.813052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ─── Cell 12: Full Validation Confusion Matrix and Classification Report ────────\n\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nmodel.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device)\n        labels = labels.to(device).unsqueeze(1)\n        logits = model(images).squeeze(1).cpu().numpy()\n        probs = 1.0 / (1.0 + np.exp(-logits))\n        preds = (probs >= 0.5).astype(int)\n        all_preds.extend(preds.tolist())\n        all_labels.extend(labels.cpu().numpy().astype(int).tolist())\n\ncm = confusion_matrix(all_labels, all_preds)\ncr = classification_report(all_labels, all_preds, target_names=[\"Non‐Meta (0)\", \"Meta (1)\"])\n\nprint(\"Confusion Matrix:\\n\", cm)\nprint(\"\\nClassification Report:\\n\", cr)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T22:30:54.644930Z","iopub.execute_input":"2025-06-01T22:30:54.645209Z","iopub.status.idle":"2025-06-01T22:33:34.077638Z","shell.execute_reply.started":"2025-06-01T22:30:54.645192Z","shell.execute_reply":"2025-06-01T22:33:34.076744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ─── Cell 13: Test‐Time Inference & Create Submission ────────────────────────────\n\ntest_ids = [f.replace(\".tif\",\"\") for f in all_test_files]\nsubmission = []\n\nfor image_id in test_ids:\n    filename = image_id + \".tif\"\n    img = Image.open(os.path.join(TEST_DIR, filename)).convert(\"RGB\")\n    img_tensor = val_transforms(img).unsqueeze(0).to(device)\n    model.eval()\n    with torch.no_grad():\n        logit = model(img_tensor).item()\n        prob = 1.0 / (1.0 + np.exp(-logit))\n    submission.append((image_id, prob))\n\nsub_df = pd.DataFrame(submission, columns=[\"id\", \"label\"])\nsub_df.to_csv(\"submission.csv\", index=False)\nprint(\"Saved submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T22:33:34.079164Z","iopub.execute_input":"2025-06-01T22:33:34.079447Z","iopub.status.idle":"2025-06-01T22:43:12.887917Z","shell.execute_reply.started":"2025-06-01T22:33:34.079423Z","shell.execute_reply":"2025-06-01T22:43:12.887148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ─── Cell 14: Discussion / Conclusion Notes ───────────────────────────────────────\n\n**Summary of Work:**\n\n1. **Data Loading & Exploration**  \n   - We loaded 220,025 labeled patches (96×96) from `train/` and inspected their class balance.  \n   - We visualized several random positive/negative patches.\n\n2. **Data Preparation**  \n   - Computed approximate per-channel mean/std on 2,000 random samples for normalization.  \n   - Performed an 80/20 stratified train/validation split.  \n   - Built a custom `Dataset` and `DataLoader` to read patches directly from disk.\n\n3. **Model Building**  \n   - Defined a small CNN (`TinyCNN`) with two convolutional layers plus a two-layer MLP head.  \n   - Moved the model to GPU (if available), used `BCEWithLogitsLoss` + Adam optimizer.\n\n4. **Training & Validation**  \n   - Trained for **5 epochs**, tracking average training loss, train‐subset AUC, and val‐subset AUC each epoch.  \n   - Observed fast convergence:  \n     - Epoch 1: Train Loss 0.3746 → Val Subset AUC 0.9225  \n     - Epoch 2: Train Loss 0.3593 → Val Subset AUC 0.9299  \n     - Epoch 3: Train Loss 0.3453 → Val Subset AUC 0.9367  \n     - Epoch 4: Train Loss 0.3311 → Val Subset AUC 0.9402 (**best**)  \n     - Epoch 5: Train Loss 0.3206 → Val Subset AUC 0.9393  \n   - Final validation accuracy ≈ 0.87, F1‐scores ~0.84–0.89.\n\n5. **Results & Next Steps**  \n   - We generated a `submission.csv` on the 57k‐image test set.  \n   - **Next improvements**: experiment with deeper architectures (ResNet50, EfficientNet), add more augmentations, fine‐tune a pretrained model, and run longer/more epochs.\n\n**Conclusion:**  \nOur TinyCNN achieved a validation‐subset AUC ≈ 0.9402 after 4 epochs. This baseline can be improved by adopting transfer learning (e.g., ResNet50) or stronger augmentation. \nThe full pipeline—from raw `train/` patches → model training → submission generation—is contained in this notebook.\n\n---\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Problem & Data Description\nObjective:\nThe goal of this project is to build a binary classification model that can automatically detect metastatic (cancerous) tissue in small histopathology image patches. Each patch is a 96×96 RGB image extracted from whole‐slide scans of lymph node sections.\n\nBackground:\nIn clinical pathology, pathologists examine stained tissue slides under a microscope to determine whether cancer has spread (metastasized) into lymph nodes. Because whole‐slide scans contain millions of pixels, it is common to divide each slide into small, uniformly‐sized patches and analyze them individually. Automating this patch‐level classification can greatly accelerate diagnosis and help ensure consistency.\n\nDataset:\n\ntrain_labels.csv (≈ 220 025 rows):\n\nid: 40‐character string identifying each patch (filename without “.tif”).\n\nlabel: Binary indicator (0 = no tumor, 1 = tumor present).\n\ntrain/ (≈ 220 025 .TIF files):\n\nEach file is named <id>.tif, containing a 96×96 RGB patch extracted from a scanned lymph node slide.\n\nThe corresponding label in train_labels.csv indicates whether the central 32×32 region of that patch contains at least one cancer‐positive pixel.\n\ntest/ (≈ 57 458 .TIF files):\n\nUnlabeled image patches (same size and format as train) for which we must predict a probability of metastatic tissue.\n\nsample_submission.csv:\n\nTemplate file listing each test patch ID and a placeholder “label” column for predicted probabilities.\n\nKey Challenges:\n\nClass Imbalance: There are more non‐metastatic patches (≈ 130 908) than metastatic ones (≈ 89 117).\n\nVisual Variability: Tumor appearance can vary widely in color, texture, and shape.\n\nComputation at Scale: With ~220 k training images and ~57 k test images, efficient data loading and model training are critical.\n\nEvaluation Metric:\nSubmissions are scored by the ROC‐AUC between the predicted probability and the true binary label on the test set. A higher area‐under‐curve indicates better discrimination between tumor and non‐tumor patches.","metadata":{}}]}